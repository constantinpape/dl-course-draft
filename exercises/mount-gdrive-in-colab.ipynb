{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "mount-gdrive-in-colab.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5SAGWYfNIkr"
      },
      "source": [
        "# Mount your google drive\n",
        "\n",
        "You can mount your google drive in colab in order to have access to permanent data storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAlRGyaUMgNI",
        "outputId": "888803bc-8f68-4c0c-94b8-e77326443b41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "# mount your google drive\n",
        "# you will need to authorize the access\n",
        "from google.colab import drive\n",
        "root = '/content/gdrive/'\n",
        "drive.mount(root)\n",
        "\n",
        "# this is the root file for your google drive\n",
        "gdrive_root = os.path.join(root, 'My Drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnUmvGGKNFW_"
      },
      "source": [
        "# now, you can access and explore the contents of your gdrive:\n",
        "gdrive_files = os.listdir(gdrive_root)\n",
        "print(gdrive_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xH65twON_rV"
      },
      "source": [
        "# make a folder to store results for this course\n",
        "res_folder = os.path.join(gdrive_root, 'dl-course')\n",
        "os.makedirs(res_folder, exist_ok=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqXhd4ye4O8t"
      },
      "source": [
        "## Save model checkpoints on your drive\n",
        "\n",
        "When running long trainings it is very convenient to save the checkpoints on the drive in order to resume training if the gpu becomes unavailable or you lose connection to colab.\n",
        "\n",
        "Below you find a small example that shows how to save checkpoints and load the checkpoint again to resume training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpta19VLOhXZ"
      },
      "source": [
        "# import the functionality from torch to train a small mnist model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# save the mnist dataset on your drive\n",
        "mnist_path = os.path.join(res_folder, 'mnist')\n",
        "ds_train = MNIST(mnist_path, download=True, transform=ToTensor())\n",
        "\n",
        "loader = DataLoader(ds_train, batch_size=8)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# the path were we will save the model and optimizer state on our drive\n",
        "state_path = os.path.join(res_folder, 'model.pth')\n",
        "\n",
        "# training for one epoch\n",
        "def train_epoch(model, loader, loss, optimizer):\n",
        "  for x, y in loader:\n",
        "    x = x.view(-1, 28 * 28)\n",
        "    pred = model(x)\n",
        "    optimizer.zero_grad()\n",
        "    loss_val = loss(pred, y)\n",
        "    loss_val.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIxykH9ydaF-",
        "outputId": "dd6f3171-c935-4c0e-9e6b-e5e95e0b5371",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train a linear model on mnist for 2 epochs and close it\n",
        "# (don't mind the choice of model etc. here, this is just a small example to \n",
        "#  show how to save and load the checkpoints)\n",
        "\n",
        "# linear layer for all pixels in an mnist image\n",
        "model = torch.nn.Linear(28 * 28, 10)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(2):\n",
        "  print(\"Training epoch\", epoch, \"...\")\n",
        "  train_epoch(model, loader, loss, optimizer)\n",
        "\n",
        "# save the state of the model and optimizer to google drive\n",
        "torch.save({'model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'epoch': epoch}, state_path)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0 ...\n",
            "Training epoch 1 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcjBvTymeXvf",
        "outputId": "041e1b08-d626-45fb-8911-7c75bc9cf5d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load the model again and continue training\n",
        "# you can execute this without running the above cell and continue training from\n",
        "# the saved checkpoint\n",
        "model = torch.nn.Linear(28 * 28, 10)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "state = torch.load(state_path)\n",
        "model.load_state_dict(state['model'])\n",
        "optimizer.load_state_dict(state['optimizer'])\n",
        "\n",
        "start_epoch = state['epoch'] + 1\n",
        "for epoch in range(start_epoch, start_epoch + 2):\n",
        "  print(\"Training epoch\", epoch, \"...\")\n",
        "  train_epoch(model, loader, loss, optimizer)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training epoch 2 ...\n",
            "Training epoch 3 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVpS0hPTljLr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}