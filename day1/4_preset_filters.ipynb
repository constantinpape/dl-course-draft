{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preset filters\n",
    "\n",
    "In this exercise, we will try to improve the model performance by giving the model additional features as input.\n",
    "Here, we will use rather simple convolutional features and use them as input to the MLP model from the previous\n",
    "exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tensorboard extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch and other libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cifar2png in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (0.0.4)\n",
      "Requirement already satisfied: numpy in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (from cifar2png) (1.19.1)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (from cifar2png) (2.24.0)\n",
      "Requirement already satisfied: six in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (from cifar2png) (1.15.0)\n",
      "Requirement already satisfied: Pillow>=6.2.0 in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (from cifar2png) (7.2.0)\n",
      "Requirement already satisfied: tqdm in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (from cifar2png) (4.48.2)\n",
      "Requirement already satisfied: pathlib in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (from cifar2png) (1.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (from requests>=2.20.0->cifar2png) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (from requests>=2.20.0->cifar2png) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (from requests>=2.20.0->cifar2png) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/pape/Work/software/conda/miniconda3/envs/adl-course/lib/python3.8/site-packages (from requests>=2.20.0->cifar2png) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install cifar2png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, training will run on the CPU\n"
     ]
    }
   ],
   "source": [
    "# check if we have gpu support\n",
    "# colab offers free gpus, however they are not activated by default.\n",
    "# to activate the gpu, go to 'Runtime->Change runtime type'. \n",
    "# Then select 'GPU' in 'Hardware accelerator' and click 'Save'\n",
    "have_gpu = torch.cuda.is_available()\n",
    "# we need to define the device for torch, yadda yadda\n",
    "if have_gpu:\n",
    "    print(\"GPU is available\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"GPU is not available, training will run on the CPU\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in google colab to get the utils.py file\n",
    "!wget https://raw.githubusercontent.com/constantinpape/training-deep-learning-models-for-vison/master/day1/utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will reuse the training function, validation function and\n",
    "# data preparation from the previous notebook\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output dir `cifar10` already exists. Please specify a different output path\r\n"
     ]
    }
   ],
   "source": [
    "cifar_dir = './cifar10'\n",
    "!cifar2png cifar10 cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = os.listdir('./cifar10/train')\n",
    "categories.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters\n",
    "\n",
    "We will now ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a list of filters as on the fly transformation. \n",
    "def apply_filters(image, target, filter_list, keep_image=False):    \n",
    "    filtered = [image] if keep_image else [] \n",
    "    for filter_function in filter_list:\n",
    "        filtered.append(filter_function(image))\n",
    "    data = np.concatenate(filtered, axis=-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the initial MLP from the previous exercise\n",
    "from utils import SimpleMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset with filter transformations\n",
    "import skimage.filters as sk_filters\n",
    "\n",
    "filters = [sk_filters.gaussian, sk_filters.laplace]\n",
    "filters = partial(apply_filters,\n",
    "                  filter_list=filters,\n",
    "                  keep_image=True)\n",
    "\n",
    "trafos = [\n",
    "    filters,\n",
    "    utils.normalize,\n",
    "    utils.to_channel_first,\n",
    "    utils.to_tensor\n",
    "]\n",
    "trafos = partial(utils.compose, transforms=trafos)\n",
    "\n",
    "train_dataset = utils.DatasetWithTransform(train_images, train_labels,\n",
    "                                           transform=trafos)\n",
    "val_dataset = utils.DatasetWithTransform(val_images, val_labels,\n",
    "                                         transform=trafos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_filters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-574be52cd374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# note: we have more input features now;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# for each filter 3 additional channels are added to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mn_input_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_filters\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_input_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_filters' is not defined"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "# note: we have more input features now;\n",
    "# for each filter 3 additional channels are added to the model\n",
    "n_input_channels = n_filters * 3 * 32 * 32\n",
    "model = SimpleMLP(n_input_channels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make loaders for training and validation data\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True,\n",
    "                          n_workers=8)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training for the model with preset filters\n",
    "\n",
    "n_pixels = 9 * 32 * 32  # number channels * number pixels\n",
    "n_classes = 10    \n",
    "model = LogisticRegressor(n_pixels, n_classes)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1.e-3)\n",
    "\n",
    "# you can find the results of this training run in the tensorboard\n",
    "# above as well, they will have the name 'log_reg_filters1' and\n",
    "# will be differently colored compared to the first model\n",
    "tb_logger = SummaryWriter('runs/log_reg_filters1')\n",
    "\n",
    "n_epochs = 4\n",
    "for epoch in trange(n_epochs):\n",
    "    train(model, train_loader, loss_function, optimizer,\n",
    "          device, epoch, tb_logger=tb_logger, log_image_interval=None)\n",
    "    step = (epoch + 1) * len(train_loader)\n",
    "    validate(model, val_loader, loss_function, device, step,\n",
    "             tb_logger=tb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the new model\n",
    "test_dataset = utils.DatasetWithTransform(test_images, test_labels,\n",
    "                                          transform=trafos)\n",
    "test_loader = DataLoader(test_dataset, batch_size=25)\n",
    "\n",
    "test_predictions, test_labels = validate(model, test_loader, loss_function,\n",
    "                                         device, 0, tb_logger=None)\n",
    "accuracy = metrics.accuracy_score(test_labels, test_predictions)\n",
    "print(\"Test accuracy\")\n",
    "print(accuracy)\n",
    "print()\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "utils.make_confusion_matrix(test_labels,\n",
    "                            test_predictions,\n",
    "                            categories, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced:\n",
    "- The filters we have used here can be expressed as convolutions.\n",
    "- Express the `gaussian` filter using [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) and train a model using these filters.\n",
    "- Can you also explace the `laplace` filter?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3.bkp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
